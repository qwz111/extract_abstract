{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2abf060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    " \n",
    "path = 'test.pdf'    \n",
    "\n",
    "with pdfplumber.open(path) as pdf: \n",
    "    content = ''\n",
    "    for i in range(len(pdf.pages)):\n",
    "    \t# 读取PDF文档第i+1页\n",
    "        page = pdf.pages[i] \n",
    " \n",
    "        # page.extract_text()函数即读取文本内容，下面这步是去掉文档最下面的页码\n",
    "        page_content = '\\n'.join(page.extract_text().split('\\n')[:-1])\n",
    "        content = content + page_content\n",
    " \n",
    " \n",
    "# # 提取以上解析结果中，“地方法规”和“2.其他有关资料”之间的内容\n",
    "# result = content.split('地方法规列举如下：')[1].split('2.其他有关资料')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "924e387e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'云南民族大学学报(自然科学版)JournalofYunnanMinzuUniversity(NaturalSciencesEdition)ISSN1672-8513,CN53-1192/N《云南民族大学学报(自然科学版)》网络首发论文题目：基于改进YOLOv5算法的车辆目标检测作者：刘超阳，曲金帅，范菁，左金花，唐玉敏网络首发日期：2022-04-21引用格式：刘超阳，曲金帅，范菁，左金花，唐玉敏．基于改进YOLOv5算法的车辆目标检测[J/OL]．云南民族大学学报(自然科学版).https://kns.cnki.net/kcms/detail/53.1192.N.20220421.0940.015.html网络首发：在编辑部工作流程中，稿件从录用到出版要经历录用定稿、排版定稿、整期汇编定稿等阶段。录用定稿指内容已经确定，且通过同行评议、主编终审同意刊用的稿件。排版定稿指录用定稿按照期刊特定版式（包括网络呈现版式）排版后的稿件，可暂不确定出版年、卷、期和页码。整期汇编定稿指出版年、卷、期、页码均已确定的印刷或数字出版的整期汇编稿件。录用定稿网络首发稿件内容必须符合《出版管理条例》和《期刊出版管理规定》的有关规定；学术研究成果具有创新性、科学性和先进性，符合编辑部对刊文的录用要求，不存在学术不端行为及其他侵权行为；稿件内容应基本符合国家有关书刊编辑、出版的技术标准，正确使用和统一规范语言文字、符号、数字、外文字母、法定计量单位及地图标注等。为确保录用定稿网络首发的严肃性，录用定稿一经发布，不得修改论文题目、作者、机构名称和学术内容，只可基于编辑规范进行少量文字的修改。出版确认：纸质期刊编辑部通过与《中国学术期刊（光盘版）》电子杂志社有限公司签约，在《中国学术期刊（网络版）》出版传播平台上创办与纸质期刊内容一致的网络版，以单篇或整期出版形式，在印刷出版之前刊发论文的录用定稿、排版定稿、整期汇编定稿。因为《中国学术期刊（网络版）》是国家新闻出版广电总局批准的网络连续型出版物（ISSN2096-4188，CN11-6037/Z），所以签约期刊的网络版上网络首发论文视为正式出版。网络首发时间：2022-04-2114:39:32网络首发地址：https://kns.cnki.net/kcms/detail/53.1192.N.20220421.0940.015.html基于改进YOLOv5算法的车辆目标检测刘超阳1，曲金帅2，范菁，左金花，唐玉敏（云南民族大学云南省高校信息与通信安全灾备重点实验室，云南昆明650500）摘要：在自动驾驶系统中车辆目标检测是一个关键内容和基本任务，为了确保上路安全，需要能够精准地检测出路面上所有目标。为了解决车辆目标检测中准确率低的问题，文章提出了一种基于改进YOLOv5算法的车辆目标检测。改进后的YOLOv5算法主要是在原来的基础上通过K-means聚类的方法对数据集中的目标边框进行重新聚类、并将CIoU损失函数和DIoU_nms应用于YOLOv5算法来提高目标识别效果。改进后的YOLOv5算法，目标检测mAP达到了85.8%，比改进前的YOLOv5算法提升了1.3%。关键词：目标检测；YOLOv5；深度学习中图分类号：O213.2文献标志码：AVehicletargetdetectionbasedonimprovedYOLOv5algorithmLIUChao-yang,QUJin-shuai,FANJing,ZUOJin-hua,TANGYu-min(UniversityKeyLaboratoryofInformationandCommunicationonSecurityBackupandRecoveryinYunnanProvince，YunnanNationalitiesUniversity，Kunming650500，China)Abstract:Intheautomaticdrivingsystem,vehicletargetdetectionisakeycontentandbasictask.Inordertoensureroadsafety,itisnecessarytoaccuratelydetectalltargetsontheroad.Inordertosolvetheproblemoflowaccuracyinvehicletargetdetection,thearticleproposesavehicletargetdetectionalgorithmbasedonimprovedYOLOv5.TheimprovedYOLOv5algorithmmainlyre-clustersthetargetbordersinthedatasetthroughtheK-meansclusteringmethodontheoriginalbasis,andappliestheCIoUlossfunctionandDIoU_nmstotheYOLOv5networktoimprovethetargetrecognitioneffect.WiththeimprovedYOLOv5algorithm,thetargetdetectionmAPreached85.8%,whichis1.3%higherthanthepreviousYOLOv5algorithm.Keywords:TargetDetection;YOLOv5;DeepLearning0引言当前，随着汽车市场需求不断变化和汽车行业的飞速的发展,自动驾驶已经成为汽车驾驶领域的重要研究热点之一。然而,在自动驾驶应用场景下,目标检测技术是计算机视觉中的一个热点问题。车辆目标检测系统是自动安全驾驶检测技术的重要组成内容,为了确保上路安全,需要能够精准地检测出路面上所有目标。因此，高效精准的车辆目标检测技术对自动驾驶系统的发展起到至关重要的作用。1刘超阳（1997-），男，辽宁辽阳人，硕士研究生在读。Liuchaoyang0317@163.com。2曲金帅（1989-），男，辽宁辽阳人，硕士，助理研究员，研究方向为深度学习、信息安全，目标元素检测方法即对一个图像信息中的具有可变元素数量的每个目标元素进行精准定位和精确分类，最终得到图像中多个目标的类别以及在图像中的位置。目前为止，基于计算机视觉的目标检测大致分为两大类：传统的目标检测算法和基于深度学习的目标检测算法。传统目标检测算法流程图如图1所示，首先将输入图片中的感兴趣区域进行选择，接下来在感兴趣的区域里进行特征提取和对提取的特征进行分类。但是传统目标检测方法的三部分检测过程繁琐，计算量大，不能满足实时监测的要求。随着深度学习的发展，基于深度学习的目标检测算法被提了出来。图1传统目标检测方法流程图基于深度学习的目标检测算法主要通过CNN完成目标特征提取工作，最后通过分类回归层完成目标的分类和定位工作。分为两大类：Two-stage目标检测算法和One-stage目标检测算法。Two-stage目标检测算法会先生成一些候选区域(regionproposals)，这些区域有可能会包含一个待检测目标，紧接着再采取一些后续措施来区分每个候选区域里具体包含了那些目标。例如R-CNN[1]、FastR-CNN[2]、FasterR-CNN[3]等；One-stage目标检测算法主要通过一遍网络得出目标的位置和类别信息，例如SSD[4]和YOLO[5-7]等。所以，One-stage目标检测算法整个过程只需要一步速度比较快。基于深度学习的目标检测算法在车辆目标检测领域吸引了许多研究人员。刘云霄等[8]人提出一种多任务卷积神经网络（Multi-TaskCascadedConvolutionalNetwork，MTCNN），该神经网络用于检测在城市道路，并且在雨雾雪天气等复杂环境场景下的检测精度较好。王聪等[9]人随后提出了一种深度融合多层卷积残差特征神经网络(convolutionalneuralnetwork,cnn)的多层高级车辆残差特征重用检测残差神经网络重用技术网络模型,他将不同的卷积残差神经网络特征分别计算进行高层深度识别融合,并且对各种深度融合后的所有高层车辆残差特征重用检测数据通道分别计算进行残差特征权重加权,提升了各种类型高层车辆残差特征重用检测的图像标准计算精度。REDMONJ等[10]人随后再次提出一种通过高层残差特征神经网络技术，实现残差特征深度识别图像的多层车辆深度卷积高层残差特征神经网络(featurereuse-resnet,fr-resnet),以车辆高层深度残差特征神经网络技术模型为基础,通过多个低层、高层、多尺度残差特征图像输入，低层深度残差神经特征在多层车辆内部中实现特征对车辆高层深度残差特征神经网络的高层特征识别重用,在两个多层高尺度特征姿态图底层的两个车辆残差特征识别数据集上分别计算取得了较高的车辆特征重用识别图像分析计算精度。然而上述车辆目标检测都是基于非单阶段式的算法，它们的不足之处在于目标实时检测的速度较慢，对于车辆目标实时检测来说,检测的速度慢并不是有利于实时的检测车辆来对目标。为了满足实时车辆目标检测文章选择了yolo系列的YOLOv5算法，并以YOLOv5模型为基础通过K-means聚类重新获取数据集的边界框，更换原网络中的损失函数和非极大值抑制，对车辆目标检测效果良好，同时也改善了遮挡目标的检测。1改进YOLOv5算法目标检测模型1.1基于K-means聚类的先验框重选取在大多数场景下原始数据集中的数据并不能满足理想训练的需求，如果想要获取更多的数据量不仅仅会为其增加训练的成本也会带来更多的工作量。为了获得更好的数据集，最好的方式是对原始数据集进行适当的数据预处理。原YOLOv5算法方法是通过对应的coco数据集的设计聚类网络来设计生成9个anchorboxes,每个不同尺寸的锚点特征结构图分别表示对应3个anchorboxes。聚类网络训练阶段,需要通过计算真实框与哪个anchorboxes的间距IoU最大,标记确定该真实锚框与其对应的锚点置信度差值为1。Anchorboxes用来预测boundingbox的，YOLOv5算法中的anchorboxes是由COCO数据集得到的，在这些anchorboxes中，目标大小的差距是很大，如果是使用自己的数据集做目标检测，那么其中部分anchor的设计并不是最合理。文章采用的是KITTI数据集对改进后的YOLOv5算法进行测试，为了得到KITTI数据集最适合的anchorbox，通过采用k-means检测方法随机计算每个锚框的目标大小,即首先随机依次选取一个数据找到集中k个点将其作为集合聚类产物中心,然后针对每个数据集中的每个聚合样本类别计算其中找到集中k个点的聚合分类产物中心的目标距离并将其进行分类后放到目标距离最小的一个聚类产物中心所在相对应的样本类别中,接着再针对每个样本类别重新随机计算一个聚类产物中心,最后再次重复上述2个计算步骤,直到每个聚类产物中心的目标位置不再发生变化。通过计算K-means方法得到的每个锚框大小尺度有效地大大提升了它的yolov5算法图2K-means聚类分析结果图1.2边界框检测Loss的改进目前基于Anchor预测机制的最小目标检测主要应用是通过测量最小化目标预测其中框物体坐标与扩大目标预测框物体坐标的高度均方差距离来不断改进目标预测框中物体的测量精度。在原始YOLOv5算法中IoU_Lossv[11]损失函数采用的是GIoU_Loss损失函数。GIoU_Loss也可以是一种损失函数的距离度量,可以直接满足基本损失距离函数的度量要求,同时由于GIoU_Loss还具有一种具有强的尺度不变性，表达式如下：c\\uf02db\\uf055bgtL\\uf03d1\\uf02dIoU\\uf02bGIoUc但是GIoU_Loss存在着两框包含的时候，GIOU_Loss会退化成IOU_Loss和GIOU_Loss需要迭代很多次才能收敛，考虑到GIou的缺点，文章引入了CIoU_Loss,表达式如下：\\uf028\\uf029\\uf0722b,bgtL\\uf03d1\\uf02dIoU\\uf02b\\uf02b\\uf061\\uf075CIoUc2\\uf061vb,bgt其中：为权重，衡量长宽比的相似度，分别表示预测框和目标框的中心点，\\uf072c两者之间距离采用欧式距离。表示能同时包含预测框和目标框的最小包围框的斜距。CIoU_Loss能够直接最小化预测框和真实框的中心点距离加速收敛，同时它还增加了可以检测真实框不同尺度的距离loss,增加了长和宽的loss,这样整个预测框就会更加的完全符合真实框。所以文章中CIoU_Loss代替原来的GIoU_Loss，效果会更好。1.3非极大值抑制nms改进在目标检测算法的最后处理阶段中，针对多目标框的筛选问题，通常需要非极大值（Non-maximumsuppression，NMS）算法去选择目标框，而在NMS算法里有一个步是需要计算当前score最大的框和其他框的IoU大小的。针对这一步，我们可以进行改进，改变IoU传统的NMS主要用于对预测框的筛选，通过IoU索引来抑制冗余的预测框，而重叠部分会使筛选存在错误筛选信息。抑制冗余的预测框不仅要考虑重叠部分，也要考虑预测框和目标框的中心点距离。DIoU则同时考虑到上述两个问题。因此，文章中将原网络的NMS更改为DIoU_NMS，所以在针对重叠多个目标的网络检测中，DIOU_nms的检测效果明显优于传统的nms算法，如图3所示，公式如下所示。\\uf0eck,IoU\\uf02dR(N,B)\\uf03c\\uf065k\\uf03d\\uf0ediDIoUii0,IoU\\uf02dR(N,B)\\uf03e\\uf065\\uf0eeDIoUiB\\uf0c7BgtIoU\\uf03dB\\uf0c8Bgt\\uf0722(b,bgt)R\\uf03dDIoUc2k\\uf065其中：IoU表示预测框与目标框的交并比，为NMS阈值，i为每个不同类别分类得分值[12]。图3NMS改进前后对比2实验结果和分析2.1实验配置本实验的模型训练的实验环境为：Intel(R)Xeon(R)Gold5218RCPU，软件平台Ubuntu，后的YOLOv5算法分别进行训练，训练模型的参数设置如表1所示，Epochs设为300，Batchsize是指一次训练的样本数目，与显卡的显存大小有关，将其设为15，输入的分辨率值为为640×640，初始学习率为0.01，动量为0.937，预设衰减系数0.0005，训练模型为YOLOv5s。表1实验参数配置表参数名称参数值WeightYolov5s.ptEpochs300Batchsize15初始学习率0.01动量0.937预设衰减系数0.00052.2数据集文章的实验数据集采用KITTI数据集对模型进行测试，KITTI数据集由德国卡尔斯鲁厄理工学院和丰田美国技术研究院联合创办，是目前国际上最大的自动驾驶场景下的计算机视觉算法评测数据集。并将实验数据集按9:1分成实验训练集与随机验证集。训练过程中，对组成训练集的实验图片分别通过Mosaic数据增强[13]方式对数据进行增强,由随机图片缩放、随机图片裁剪、随机转换排列拼接,构成新的数据图像用于车辆目标检测。将数据集里的图片模仿VOC2007数据集栺式，利用Labelimg标注软件依次对这些图片中的车辆进行标注外围框，转化为训练所需要的xml格式，从而就可以制作出目标模型检测的数据集。2.3评价标准在目标检测领域，一般使用召回率(Recall)、精准率(Precision)和综合前两者的mAP对目标检测算法性能进行评价。召回率(Recall)：目标召回的概率仍然可以是针对某一个具体目标类别而言的,即我们预测正确的一个目标框和所有目标GroundTruth框的一个比值，公式为：TPRecall\\uf03d\\uf0b4100%TP\\uf02bFN精准率(Precision)：精准率通常是针对某一个具体正例类别而言的,用于精确描述通过预测计算出来的一个正例类别占所有正常实例的最小比率,公式为：TPPrecision\\uf03d\\uf0b4100%但一般情况下召回率和精准率很难都维持在高水平，由此就需要一个参数来综合这两个参数，使用mAP值来衡量检测网络的算法性能，其适用于多标签图像分类，计算公式如下：N\\uf0e5P(k)\\uf044R(k)mAP\\uf03dk\\uf03d1C式中的N表示val集中的样本个数，P(k)是精准率Precision在同时识别k个样本时的大小，\\uf044R(k)表示召回率Recall在检测样本个数从k\\uf02d1个变为k个时的变化情况，C则是多分类检测仸务重类别的个数。3实验结果和分析如图4所示，可以看出来改进后的YOLOv5算法的map曲线比原来的网络有所提高，并且与原来的算法相比精度也有所提升。改进前后的YOLOv5算法的各种重要指标取值如下表2所示。从表2中我们可以明显看出,文章提出的改进方法将模型的map提升了1.3%，达到了85.80%。在精度和召回率方面，相比较原来的方法分别提升了0.8%和0.6%，证明了文章的方法能够有效地提高对车辆的目标检测能力。图4改进前后的YOLOv5实验对比图表2综合指标测试结果模型P%R%mAp%YOLOv585.380.984.5改进后YOLOv586.181.785.8文章提出了对YOLOv5算法的改进，为了突出改进算法的优点，本实验采用了对比的分别包括Tiny_YOLOv3算法[14]、YOLOv3[7]算法、FasterRCNN[2]算法和R-FCN[15]算法。其中，在对主流算法训练时选取与YOLOv5算法相同的数据集，对比结果如表3所示。表3在KITTI数据集上与其他算法对比结果模型P%R%mAP%Tiny_YOLOv386.8660.2458.69YOLOv384.4177.5176.82FasterRCNN//78.96R-FCN//83.27改进后的YOLOv586.1081.7085.80从表3可知，改进后的YOLOv5算法能够有效地提高精准率、召回率和mAP。通过改进损失函数和非极大值抑制的算法是的map较R-FCN模型提升了2.53%，达到了85.80%，其余的3种模型的mAP的值全都在80%以下。并且精准率和召回率较YOLOv3算法分别提升了1.69%和4.19%。由表可知文章的模型效果比其他四种模型的效果更好，更适合用于车辆目标检测。如图5、6所示，展示了改进前后YOLOv5算法的测试效果图，从图中可以看出改进后的YOLOv5算法检测效果比原来的方法有所提升，并且改善了原来YOLOv5算法对目标的漏检，右下角的图片相比于右上角的图片不仅在检测精度方面提升，而且还把原来漏检的目标也给检测出来了。证明了文章方法的检测效果更好。图5改进前YOLOv5测试结果图6改进前后YOLOv5测试对比结果4结论为了准确的检测出图像中的车辆，解决漏检和遮挡的问题，提出了基于改进了YOLOv5算法的车辆目标检测。YOLOv5以YOLOv5s预训练模型为载体，通过K-means聚类算法优化初始锚框，设置损失函数为CIoU+DIoU_NMS等方法优化YOLOv5算法。与原始YOLOv5算法相比平均检测精度提高1.3%；与YOLOv3算法、FasterRCNN算法、R-FCN算法和Tiny_YOLOv3算法对比，改进的YOLOv5算法的准确率和召回率更高，能较准确的检测出目标车辆。实验表明文章中提出的方法具有一定的可行性。参考文献[1]GirshickR,DonahueJ,DarrellT,etal.Richfeaturehierarchiesforaccurateobjectdetectionandsemanticsegmentation[C].ProceedingsoftheIEEEconferenceoncomputervisionandpatternr-ecognition,2014:580-587.[2]GIRSHICKR.FastR-CNN[C]//2015IEEEInternationalConferenceonComputerVision(ICCV).NewYork:IEEE,2015:1440-1448.[3]RENSQ,HEKM,GIRSHICKR,etal.FasterRCNN:Towardsreal-timeobjectdetectionwithregionproposalnetworks[C]//IEEETransactionPatternAnalysisandMachineIntelligence.NewYork:IEEE,2019:1137-1149.[4]LiuW,AnguelovD,ErhanD,etal.Ssd:Singleshotmultiboxdetector[C].Europeanconferenceoncomputervision.Springer,Cham,2016:21-37.[5]RedmonJ,DivvalaS,GirshickR,etal.Youonlylookonce:Unified,real-timeobjectdetection[C].ProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,2016,LasVegas,779-788.[6]RedmonJ,FarhadiA.YOLO9000:better,faster,stronger[C].ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2017:7263-7271.[7]RedmonJ,FarhadiA.Yolov3:Anincrementalimprovement[J].arXivpreprintarXiv:1804.02767,2018.[8]刘云霄，王敬东，黄雨秋，等.MTCNN的改进及其在道路车辆检测中的应用［J］.光电子技术，2019，39（3）：196-204，224.[9]王聪.基于深度学习的无人机单目标识别与跟踪算法研究［D］.厦门：华侨大学，2019：14-16.[10]RedmonJ,FarhadiA.YOLO9000:Better,Faster,Stronger[C]//IEEEConferenceonComputerVision&PatternRecognition.IEEE,2017:6517-6525.[11]张麒麟,林清平,肖蕾.改进YOLOv5的航拍图像识别算法[J].长江信息通信,2021,34(3):73-76.[12]ShileiTan,GonglinLu,ZiqiangJiang,etal.ImprovedYOLOv5NetworkModelandApplicationinSafetyHelmetDetection[J].Proceedingsofthe2021IEEEInternationalConferenceonIntelligenceandSafetyforRobotics.Nagoya,Japan.[13]BochkovskiyA,WangCY,LiaoH.YOLOv4:OptimalSpeedandAccuracyofObjectDetection[J].arXivpreprintarXiv:2004.10934,2020.[14]张洋.改进的YOLOv3-tiny在城市交叉路口车辆检测中的应用[D].重庆师范大学,2020.DOI:10.27672/d.cnki.gcsfc.2020.000818.[15]DaiJ,LiY,HeK,etal.R-fcn:Objectdetectionviaregion-basedfullyconvolutionalnetworks[C]//Advancesinneuralinformationprocessingsystems.2016:379-387.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = content.replace('\\n','')\n",
    "content = content.replace(' ','')\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a2c8375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "：在自动驾驶系统中车辆目标检测是一个关键内容和基本任务，为了确保上路安全，需要能够精准地检测出路面上所有目标。为了解决车辆目标检测中准确率低的问题，文章提出了一种基于改进YOLOv5算法的车辆目标检测。改进后的YOLOv5算法主要是在原来的基础上通过K-means聚类的方法对数据集中的目标边框进行重新聚类、并将CIoU损失函数和DIoU_nms应用于YOLOv5算法来提高目标识别效果。改进后的YOLOv5算法，目标检测mAP达到了85.8%，比改进前的YOLOv5算法提升了1.3%。关键词：目标检测；YOLOv5；深度学习中图分类号：O213.2文献标志码：AVehicletargetdetectionbasedonimprovedYOLOv5algorithmLIUChao-yang,QUJin-shuai,FANJing,ZUOJin-hua,TANGYu-min(UniversityKeyLaboratoryofInformationandCommunicationonSecurityBackupandRecoveryinYunnanProvince，YunnanNationalitiesUniversity，Kunming650500，China)Abstract:Intheautomaticdrivingsystem,vehicletargetdetectionisakeycontentandbasictask.Inordertoensureroadsafety,itisnecessarytoaccuratelydetectalltargetsontheroad.Inordertosolvetheproblemoflowaccuracyinvehicletargetdetection,thearticleproposesavehicletargetdetectionalgorithmbasedonimprovedYOLOv5.TheimprovedYOLOv5algorithmmainlyre-clustersthetargetbordersinthedatasetthroughtheK-meansclusteringmethodontheoriginalbasis,andappliestheCIoUlossfunctionandDIoU_nmstotheYOLOv5networktoimprovethetargetrecognitioneffect.WiththeimprovedYOLOv5algorithm,thetargetdetectionmAPreached85.8%,whichis1.3%higherthanthepreviousYOLOv5algorithm.Keywords:TargetDetection;YOLOv5;DeepLearning0引言当前，随着汽车市场需求不断变化和汽车行业的飞速的发展,自动驾驶已经成为汽车驾驶领域的重要研究热点之一。然而,在自动驾驶应用场景下,目标检测技术是计算机视觉中的一个热点问题。车辆目标检测系统是自动安全驾驶检测技术的重要组成内容,为了确保上路安全,需要能够精准地检测出路面上所有目标。因此，高效精准的车辆目标检测技术对自动驾驶系统的发展起到至关重要的作用。1刘超阳（1997-），男，辽宁辽阳人，硕士研究生在读。Liuchaoyang0317@163.com。2曲金帅（1989-），男，辽宁辽阳人，硕士，助理研究员，研究方向为深度学习、信息安全，目标元素检测方法即对一个图像信息中的具有可变元素数量的每个目标元素进行精准定位和精确分类，最终得到图像中多个目标的类别以及在图像中的位置。目前为止，基于计算机视觉的目标检测大致分为两大类：传统的目标检测算法和基于深度学习的目标检测算法。传统目标检测算法流程图如图1所示，首先将输入图片中的感兴趣区域进行选择，接下来在感兴趣的区域里进行特征提取和对提取的特征进行分类。但是传统目标检测方法的三部分检测过程繁琐，计算量大，不能满足实时监测的要求。随着深度学习的发展，基于深度学习的目标检测算法被提了出来。图1传统目标检测方法流程图基于深度学习的目标检测算法主要通过CNN完成目标特征提取工作，最后通过分类回归层完成目标的分类和定位工作。分为两大类：Two-stage目标检测算法和One-stage目标检测算法。Two-stage目标检测算法会先生成一些候选区域(regionproposals)，这些区域有可能会包含一个待检测目标，紧接着再采取一些后续措施来区分每个候选区域里具体包含了那些目标。例如R-CNN[1]、FastR-CNN[2]、FasterR-CNN[3]等；One-stage目标检测算法主要通过一遍网络得出目标的位置和类别信息，例如SSD[4]和YOLO[5-7]等。所以，One-stage目标检测算法整个过程只需要一步速度比较快。基于深度学习的目标检测算法在车辆目标检测领域吸引了许多研究人员。刘云霄等[8]人提出一种多任务卷积神经网络（Multi-TaskCascadedConvolutionalNetwork，MTCNN），该神经网络用于检测在城市道路，并且在雨雾雪天气等复杂环境场景下的检测精度较好。王聪等[9]人随后提出了一种深度融合多层卷积残差特征神经网络(convolutionalneuralnetwork,cnn)的多层高级车辆残差特征重用检测残差神经网络重用技术网络模型,他将不同的卷积残差神经网络特征分别计算进行高层深度识别融合,并且对各种深度融合后的所有高层车辆残差特征重用检测数据通道分别计算进行残差特征权重加权,提升了各种类型高层车辆残差特征重用检测的图像标准计算精度。REDMONJ等[10]人随后再次提出一种通过高层残差特征神经网络技术，实现残差特征深度识别图像的多层车辆深度卷积高层残差特征神经网络(featurereuse-resnet,fr-resnet),以车辆高层深度残差特征神经网络技术模型为基础,通过多个低层、高层、多尺度残差特征图像输入，低层深度残差神经特征在多层车辆内部中实现特征对车辆高层深度残差特征神经网络的高层特征识别重用,在两个多层高尺度特征姿态图底层的两个车辆残差特征识别数据集上分别计算取得了较高的车辆特征重用识别图像分析计算精度。然而上述车辆目标检测都是基于非单阶段式的算法，它们的不足之处在于目标实时检测的速度较慢，对于车辆目标实时检测来说,检测的速度慢并不是有利于实时的检测车辆来对目标。为了满足实时车辆目标检测文章选择了yolo系列的YOLOv5算法，并以YOLOv5模型为基础通过K-means聚类重新获取数据集的边界框，更换原网络中的损失函数和非极大值抑制，对车辆目标检测效果良好，同时也改善了遮挡目标的检测。1改进YOLOv5算法目标检测模型1.1基于K-means聚类的先验框重选取在大多数场景下原始数据集中的数据并不能满足理想训练的需求，如果想要获取更多的数据量不仅仅会为其增加训练的成本也会带来更多的工作量。为了获得更好的数据集，最好的方式是对原始数据集进行适当的数据预处理。原YOLOv5算法方法是通过对应的coco数据集的设计聚类网络来设计生成9个anchorboxes,每个不同尺寸的锚点特征结构图分别表示对应3个anchorboxes。聚类网络训练阶段,需要通过计算真实框与哪个anchorboxes的间距IoU最大,标记确定该真实锚框与其对应的锚点置信度差值为1。Anchorboxes用来预测boundingbox的，YOLOv5算法中的anchorboxes是由COCO数据集得到的，在这些anchorboxes中，目标大小的差距是很大，如果是使用自己的数据集做目标检测，那么其中部分anchor的设计并不是最合理。文章采用的是KITTI数据集对改进后的YOLOv5算法进行测试，为了得到KITTI数据集最适合的anchorbox，通过采用k-means检测方法随机计算每个锚框的目标大小,即首先随机依次选取一个数据找到集中k个点将其作为集合聚类产物中心,然后针对每个数据集中的每个聚合样本类别计算其中找到集中k个点的聚合分类产物中心的目标距离并将其进行分类后放到目标距离最小的一个聚类产物中心所在相对应的样本类别中,接着再针对每个样本类别重新随机计算一个聚类产物中心,最后再次重复上述2个计算步骤,直到每个聚类产物中心的目标位置不再发生变化。通过计算K-means方法得到的每个锚框大小尺度有效地大大提升了它的yolov5算法图2K-means聚类分析结果图1.2边界框检测Loss的改进目前基于Anchor预测机制的最小目标检测主要应用是通过测量最小化目标预测其中框物体坐标与扩大目标预测框物体坐标的高度均方差距离来不断改进目标预测框中物体的测量精度。在原始YOLOv5算法中IoU_Lossv[11]损失函数采用的是GIoU_Loss损失函数。GIoU_Loss也可以是一种损失函数的距离度量,可以直接满足基本损失距离函数的度量要求,同时由于GIoU_Loss还具有一种具有强的尺度不变性，表达式如下：cbbgtL1IoUGIoUc但是GIoU_Loss存在着两框包含的时候，GIOU_Loss会退化成IOU_Loss和GIOU_Loss需要迭代很多次才能收敛，考虑到GIou的缺点，文章引入了CIoU_Loss,表达式如下：2b,bgtL1IoUCIoUc2vb,bgt其中：为权重，衡量长宽比的相似度，分别表示预测框和目标框的中心点，c两者之间距离采用欧式距离。表示能同时包含预测框和目标框的最小包围框的斜距。CIoU_Loss能够直接最小化预测框和真实框的中心点距离加速收敛，同时它还增加了可以检测真实框不同尺度的距离loss,增加了长和宽的loss,这样整个预测框就会更加的完全符合真实框。所以文章中CIoU_Loss代替原来的GIoU_Loss，效果会更好。1.3非极大值抑制nms改进在目标检测算法的最后处理阶段中，针对多目标框的筛选问题，通常需要非极大值（Non-maximumsuppression，NMS）算法去选择目标框，而在NMS算法里有一个步是需要计算当前score最大的框和其他框的IoU大小的。针对这一步，我们可以进行改进，改变IoU传统的NMS主要用于对预测框的筛选，通过IoU索引来抑制冗余的预测框，而重叠部分会使筛选存在错误筛选信息。抑制冗余的预测框不仅要考虑重叠部分，也要考虑预测框和目标框的中心点距离。DIoU则同时考虑到上述两个问题。因此，文章中将原网络的NMS更改为DIoU_NMS，所以在针对重叠多个目标的网络检测中，DIOU_nms的检测效果明显优于传统的nms算法，如图3所示，公式如下所示。k,IoUR(N,B)kiDIoUii0,IoUR(N,B)DIoUiBBgtIoUBBgt2(b,bgt)RDIoUc2k其中：IoU表示预测框与目标框的交并比，为NMS阈值，i为每个不同类别分类得分值[12]。图3NMS改进前后对比2实验结果和分析2.1实验配置本实验的模型训练的实验环境为：Intel(R)Xeon(R)Gold5218RCPU，软件平台Ubuntu，后的YOLOv5算法分别进行训练，训练模型的参数设置如表1所示，Epochs设为300，Batchsize是指一次训练的样本数目，与显卡的显存大小有关，将其设为15，输入的分辨率值为为640×640，初始学习率为0.01，动量为0.937，预设衰减系数0.0005，训练模型为YOLOv5s。表1实验参数配置表参数名称参数值WeightYolov5s.ptEpochs300Batchsize15初始学习率0.01动量0.937预设衰减系数0.00052.2数据集文章的实验数据集采用KITTI数据集对模型进行测试，KITTI数据集由德国卡尔斯鲁厄理工学院和丰田美国技术研究院联合创办，是目前国际上最大的自动驾驶场景下的计算机视觉算法评测数据集。并将实验数据集按9:1分成实验训练集与随机验证集。训练过程中，对组成训练集的实验图片分别通过Mosaic数据增强[13]方式对数据进行增强,由随机图片缩放、随机图片裁剪、随机转换排列拼接,构成新的数据图像用于车辆目标检测。将数据集里的图片模仿VOC2007数据集栺式，利用Labelimg标注软件依次对这些图片中的车辆进行标注外围框，转化为训练所需要的xml格式，从而就可以制作出目标模型检测的数据集。2.3评价标准在目标检测领域，一般使用召回率(Recall)、精准率(Precision)和综合前两者的mAP对目标检测算法性能进行评价。召回率(Recall)：目标召回的概率仍然可以是针对某一个具体目标类别而言的,即我们预测正确的一个目标框和所有目标GroundTruth框的一个比值，公式为：TPRecall100%TPFN精准率(Precision)：精准率通常是针对某一个具体正例类别而言的,用于精确描述通过预测计算出来的一个正例类别占所有正常实例的最小比率,公式为：TPPrecision100%但一般情况下召回率和精准率很难都维持在高水平，由此就需要一个参数来综合这两个参数，使用mAP值来衡量检测网络的算法性能，其适用于多标签图像分类，计算公式如下：NP(k)R(k)mAPk1C式中的N表示val集中的样本个数，P(k)是精准率Precision在同时识别k个样本时的大小，R(k)表示召回率Recall在检测样本个数从k1个变为k个时的变化情况，C则是多分类检测仸务重类别的个数。3实验结果和分析如图4所示，可以看出来改进后的YOLOv5算法的map曲线比原来的网络有所提高，并且与原来的算法相比精度也有所提升。改进前后的YOLOv5算法的各种重要指标取值如下表2所示。从表2中我们可以明显看出,文章提出的改进方法将模型的map提升了1.3%，达到了85.80%。在精度和召回率方面，相比较原来的方法分别提升了0.8%和0.6%，证明了文章的方法能够有效地提高对车辆的目标检测能力。图4改进前后的YOLOv5实验对比图表2综合指标测试结果模型P%R%mAp%YOLOv585.380.984.5改进后YOLOv586.181.785.8文章提出了对YOLOv5算法的改进，为了突出改进算法的优点，本实验采用了对比的分别包括Tiny_YOLOv3算法[14]、YOLOv3[7]算法、FasterRCNN[2]算法和R-FCN[15]算法。其中，在对主流算法训练时选取与YOLOv5算法相同的数据集，对比结果如表3所示。表3在KITTI数据集上与其他算法对比结果模型P%R%mAP%Tiny_YOLOv386.8660.2458.69YOLOv384.4177.5176.82FasterRCNN//78.96R-FCN//83.27改进后的YOLOv586.1081.7085.80从表3可知，改进后的YOLOv5算法能够有效地提高精准率、召回率和mAP。通过改进损失函数和非极大值抑制的算法是的map较R-FCN模型提升了2.53%，达到了85.80%，其余的3种模型的mAP的值全都在80%以下。并且精准率和召回率较YOLOv3算法分别提升了1.69%和4.19%。由表可知文章的模型效果比其他四种模型的效果更好，更适合用于车辆目标检测。如图5、6所示，展示了改进前后YOLOv5算法的测试效果图，从图中可以看出改进后的YOLOv5算法检测效果比原来的方法有所提升，并且改善了原来YOLOv5算法对目标的漏检，右下角的图片相比于右上角的图片不仅在检测精度方面提升，而且还把原来漏检的目标也给检测出来了。证明了文章方法的检测效果更好。图5改进前YOLOv5测试结果图6改进前后YOLOv5测试对比结果4结论为了准确的检测出图像中的车辆，解决漏检和遮挡的问题，提出了基于改进了YOLOv5算法的车辆目标检测。YOLOv5以YOLOv5s预训练模型为载体，通过K-means聚类算法优化初始锚框，设置损失函数为CIoU+DIoU_NMS等方法优化YOLOv5算法。与原始YOLOv5算法相比平均检测精度提高1.3%；与YOLOv3算法、FasterRCNN算法、R-FCN算法和Tiny_YOLOv3算法对比，改进的YOLOv5算法的准确率和召回率更高，能较准确的检测出目标车辆。实验表明文章中提出的方法具有一定的可行性。参考文献[1]GirshickR,DonahueJ,DarrellT,etal.Richfeaturehierarchiesforaccurateobjectdetectionandsemanticsegmentation[C].ProceedingsoftheIEEEconferenceoncomputervisionandpatternr-ecognition,2014:580-587.[2]GIRSHICKR.FastR-CNN[C]//2015IEEEInternationalConferenceonComputerVision(ICCV).NewYork:IEEE,2015:1440-1448.[3]RENSQ,HEKM,GIRSHICKR,etal.FasterRCNN:Towardsreal-timeobjectdetectionwithregionproposalnetworks[C]//IEEETransactionPatternAnalysisandMachineIntelligence.NewYork:IEEE,2019:1137-1149.[4]LiuW,AnguelovD,ErhanD,etal.Ssd:Singleshotmultiboxdetector[C].Europeanconferenceoncomputervision.Springer,Cham,2016:21-37.[5]RedmonJ,DivvalaS,GirshickR,etal.Youonlylookonce:Unified,real-timeobjectdetection[C].ProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,2016,LasVegas,779-788.[6]RedmonJ,FarhadiA.YOLO9000:better,faster,stronger[C].ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2017:7263-7271.[7]RedmonJ,FarhadiA.Yolov3:Anincrementalimprovement[J].arXivpreprintarXiv:1804.02767,2018.[8]刘云霄，王敬东，黄雨秋，等.MTCNN的改进及其在道路车辆检测中的应用［J］.光电子技术，2019，39（3）：196-204，224.[9]王聪.基于深度学习的无人机单目标识别与跟踪算法研究［D］.厦门：华侨大学，2019：14-16.[10]RedmonJ,FarhadiA.YOLO9000:Better,Faster,Stronger[C]//IEEEConferenceonComputerVision&PatternRecognition.IEEE,2017:6517-6525.[11]张麒麟,林清平,肖蕾.改进YOLOv5的航拍图像识别算法[J].长江信息通信,2021,34(3):73-76.[12]ShileiTan,GonglinLu,ZiqiangJiang,etal.ImprovedYOLOv5NetworkModelandApplicationinSafetyHelmetDetection[J].Proceedingsofthe2021IEEEInternationalConferenceonIntelligenceandSafetyforRobotics.Nagoya,Japan.[13]BochkovskiyA,WangCY,LiaoH.YOLOv4:OptimalSpeedandAccuracyofObjectDetection[J].arXivpreprintarXiv:2004.10934,2020.[14]张洋.改进的YOLOv3-tiny在城市交叉路口车辆检测中的应用[D].重庆师范大学,2020.DOI:10.27672/d.cnki.gcsfc.2020.000818.[15]DaiJ,LiY,HeK,etal.R-fcn:Objectdetectionviaregion-basedfullyconvolutionalnetworks[C]//Advancesinneuralinformationprocessingsystems.2016:379-387.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ret = re.match(r\"(.*)摘要(.*)\",content)\n",
    "print(ret.group(2))\n",
    "docment = ret.group(2)\n",
    "\n",
    "# docment = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff65278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pprint import pprint\n",
    "import operator\n",
    "\n",
    "\n",
    "\n",
    "def encode_sen(sen,corpus):\n",
    "    \"\"\"\n",
    "    input: sentence and corpus\n",
    "    output :  bag of words vector of sentence\n",
    "    \"\"\"\n",
    "    cv = CountVectorizer()\n",
    "    cv = cv.fit(corpus)\n",
    "    vec = cv.transform([sen]).toarray()\n",
    "    return vec[0]\n",
    "\n",
    "def cosin_distance(vector1, vector2):\n",
    "    \"\"\"\n",
    "    input: two bag of words vectors of sentence\n",
    "    output :  the similarity between the sentence\n",
    "\n",
    "    \"\"\"\n",
    "    dot_product = 0.0\n",
    "    normA = 0.0\n",
    "    normB = 0.0\n",
    "    for a, b in zip(vector1, vector2):\n",
    "        dot_product += a * b\n",
    "        normA += a ** 2\n",
    "        normB += b ** 2\n",
    "    if normA == 0.0 or normB == 0.0:\n",
    "        return None\n",
    "    else:\n",
    "        return dot_product / ((normA * normB) ** 0.5)\n",
    "\n",
    "\n",
    "def doc_list2str(doc_list):\n",
    "    \"\"\"\n",
    "    transform the doc_list to str\n",
    "    \"\"\"\n",
    "    docu_str = \"\"\n",
    "    for wordlist in doc_list:\n",
    "        docu_str += \" \".join(wordlist)\n",
    "    return docu_str\n",
    "\n",
    "\n",
    "def MMR(doc_list,corpus):\n",
    "    \"\"\"\n",
    "    input ：corpus and the docment you want to extract\n",
    "    output :the abstract of the docment\n",
    "    \"\"\"\n",
    "    Corpus = corpus\n",
    "    docu = doc_list2str(doc_list)\n",
    "    doc_vec = encode_sen(docu,Corpus)\n",
    "    QDScore = {}\n",
    "    ###calculate the  similarity of every sentence with the whole corpus\n",
    "    for sen in doc_list:\n",
    "        sen = \" \".join(sen)\n",
    "\n",
    "        sen_vec = encode_sen(sen,corpus)\n",
    "        score = cosin_distance(sen_vec,doc_vec)\n",
    "        QDScore[sen] = score\n",
    "\n",
    "\n",
    "    n = 2\n",
    "    alpha = 0.7\n",
    "    Summary_set = []\n",
    "    while n > 0:\n",
    "        MMRScore = {}\n",
    "        ### select the first sentence of abstract\n",
    "        if Summary_set == []:\n",
    "            selected = max(QDScore.items(), key=operator.itemgetter(1))[0]\n",
    "            Summary_set.append(selected)\n",
    "\n",
    "        Summary_set_str = \" \".join(Summary_set)\n",
    "\n",
    "        for sentence in QDScore.keys():\n",
    "             #calculate MMR\n",
    "            if sentence not in Summary_set:\n",
    "                sum_vec = encode_sen(Summary_set_str, corpus)\n",
    "                sentence_vec = encode_sen(sentence,corpus)\n",
    "                MMRScore[sentence] = alpha * QDScore[sentence] - (1 - alpha) * cosin_distance(sentence_vec,sum_vec)\n",
    "        selected = max(MMRScore.items(), key=operator.itemgetter(1))[0]\n",
    "        Summary_set.append(selected)\n",
    "        n -= 1\n",
    "    # print(len(Summary_set))\n",
    "    return  Summary_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3486cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "sen_list = docment.strip().split(\"。\")\n",
    "# sen_list.remove(\"\")\n",
    "doc_list = [jieba.lcut(i) for i in sen_list]\n",
    "corpus = [\" \".join(i) for i in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4418af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ''\n",
    "for s in MMR(doc_list,corpus):\n",
    "    res += s.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7850d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为了解决车辆目标检测中准确率低的问题，文章提出了一种基于改进YOLOv5算法的车辆目标检测改进后的YOLOv5算法主要是在原来的基础上通过K-means聚类的方法对数据集中的目标边框进行重新聚类、并将CIoU损失函数和DIoU_nms应用于YOLOv5算法来提高目标识别效果目前为止，基于计算机视觉的目标检测大致分为两大类：传统的目标检测算法和基于深度学习的目标检测算法'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9da97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
