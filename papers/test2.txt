图形图李文章编号:1007-1423(2021)20-0074-06DOLI:10.3969/j.issn.1007-1423.2021.20.015基于改进的FasterR-CNN的车辆目标检测单志勇,官加辉(东华大学,上海201600)摘要:车辆目标检测作为交通管理系统的重要组成部分具有重要的研究意义。为了解决传统车辆目标检测带来的准确率低的问题,提出了基于改进的FasterR+CNN算法的车辆目标检测。改进后的FasterR-CNN算法在原始FasterR-CNN算法的基础上随机选取960x540、900x500、800x480三种尺寸的训练图片进行训练,同时对RPN(RegionProposalNetwork)中的候选区域比例进行了扩展,增加了1:3、3:1两种比例。改进后的目标检测的mAP达到了95.56%,比基于FasterR-CNN算法的车辆目标检测的mAP提高了0.06%。关键词:FasterR-CNN算法;目标检测;深度学习0“引言随着城市化进程的不断加快,交通管理系统是当前交通领域需要研究的热点问题。车辆目标检测是交通管理系统的重要组成部分之一,广泛应用在智能监控系统和智能停车系统等领域中。车辆目标检测应用在智能交通监控系统中可以加快救援速度和分析马路拥堵情况,极大的缓解了交通压力。车辆目标检测应用在智能停车系统中,通过对停车场内的停车情况进行分析,可以缓解停车难的问题。可见,车辆目标检测在交通管理系统中的应用极大地提高了交通管理的效率。所以,优化车辆目标检测问题对增强交通管理系统具有重要意义和应用价值。传统的目标检测算法流程图如图1所示。首先输人需要检测的图片,采用滑动窗口的方式进行候选框的选取,其次,采用基于人工设计特征提取“的算法,如HOC(HistogramofOrientedCradient)2对候选框进行特征提取;然后使用分类器,如SVM等进行判定,在经过分类器判定后获得的候选框会有一部分重叠,因此,需要在经过NMSI将重叠的部分筛选合并找到目标物体的最佳位置,得到最终的检测结果。习现代计算机(www.moderncomputer.cn)2021.07中分类器判定』hu目标or背景河输篷特征e框提取图1传统目标检测算法流程囹传统目标检测的不足主要体现在候选框和特征提取部分。选取候选框采用的是滑动窗口的方式,若滑动窗口的大小和步长的变化不合理,则会产生大量冗余的候选框,降低了目标检测的速度;特征提取的方法是基于人工设计的,特征提取过程中极易受到个人主观性的影响,降低了目标检测的准确率。2014年,RossCirshick等人提出了RHCNN5算法,这一算法明显提高了目标检测的速度。R-CNN算法在传统算法模型的基础上进行两个方面的调整:一是采用选择性搜索(SelectiveSearch)代替滑动窗口的方式进行候选框的选取,大约选取1000~2000个候选框,减少了计算量;其二是采用CNN代替人工设计特征提取特征图,有效避免了人为主观性的影响。2015年RossCirshick提出了FastRHCNND,弥补了R-CNN算法中输人图像需固定尺寸的不足。FastR-CNN算法的输入图像的尸寸是任意的,并丁是直接图形图李对整张图像卷积,减少了重复计算;采用ROIPooling层固定特征的尺寸,以便让特征图以合适的尺寸输人到全连接层;采用Softmax层输出目标的类别。FastR-CNN算法只需单个模型即可完成目标检测,极大地提高了检测效率。2016年RossCirshick在RH-CNN和FastR-CNN的基础上提出了FasterR-CNNW。FasterR-CNN算法采用RPN(RegionProposalNetwork)代替选择性搜索法提取候选框,并把提取候选框,选取特征图和判定目标类别和位置放置在同一个网络,解决了模型结合慢的问题,检测效率和准确率都满足了目标检测的要求,极大地提高了目标检测的综合性能。本文主要内容就是研究改进的FasterR+CNN算法在实际车辆目标检测的场景中应用,主干网络选取了VCC165预训练模型,训练和测试的样本集来自UA-DETRAC数据集,使用训练集训练目标检测模型,使用测试的样本集对得到的模型进行测试。实验结果表明使用改进的FasterRHCNN算法进行车辆目标检测具有较高的泛化能力,同时也提高了车辆目标检测的准确度和效率。1“基于改进的FasterR-CNN的车辆目标检测FasterR+CNN网络主要由以下四个内容组成:卷积层.RPN层、RoLPooling层和坐标回归层。其网络结构图如图2所示。卷积层采用VCC16预训练模型来提取特征,其网络结构由13个Conv层、13个ReLU层和4个Pooling层组成。在整个VGC16模型中,每经过一次Pooling层的输出都是输人的112。生成的fea-turemap被共享于RPN层和RoIPooling层;PRN层利用Softmax和boundingbox判断anchors所属类别和修正anchors的边框,以便获得更准确的区域建议框;ROLPooling层的输人来自卷积层生成的featuremap和RPN层的区域建议框,该层的作用就是将输人固定到统一大小并输出至坐标回归层的全连接层;坐标回归层则是用来判断目标的类别和坐标位置。FasterR-CNN模型进行训练时采用的训练图片的尺寸是恒定的,这在一定程度上降低了目标检测的效率。本文提出了多尺度训练,在960x540、900x500、800x480三种不同尺寸的训练图片中随机选取进行训练,能有效提高车辆目标检测的鲁棒性。囹2FasterR-CNN的网络结构囹1.1RPM网络Anchor是RPN网络中的一个重要概念,它与滑窗法设置的窗口大小类似,都是预设图像的参照框。原始FasterR_CNN网络中Anch0r是在RPN网络的3X3卷积层生成的,每个错点对应三种尺度缩放比和三种宽高比分别为[128,256,512]、[1:2,1:1,2:1]的9种An-chor。改进后的RPN增加了1:3、3:1两种候选区域的比例。改进前后的对比图如图3所示。(a)原始比例图3改进前后对比囹(b)改进后比例RPN是FasterR-CNN网络的核心部分,是一个完整的卷积神经网络。RPN作用在特征提取网络输出的特征图像上,首先是经过一个卷积层选取锚点,生成anchor;然后分成两路,一路输入分类层利用Softmax判断anchor的类别,在进行Softmax的前后都对输出做了Reshape,以便Softmax进行二分类和减少计算的复杂度;一路输人边框回归层用来判断anchors的边框位置,计算anchor的位置与真实框位置的偏移量并进行调整获取位置更准确的anchor;分类层和边框回归层的输出共同输人Proposal,Proposal根据Img_info提供的信息和NMS算法筛选大约2000个更准确的anchor。1.2AolPOOlingRoLPooling使得原始图片的大小可以是任意的,减少了原始图片在缩放成固定大小时带来的信息损现代计算机(www.moderncomputer.cn)_2021.07中@图形图李失;RoIPooling可以将不同尸寸的图片生成的特征囹转换为固定尸寸的特征图,帮助全连接层以及分类层更好地吸收。RoL利用MaxPooling将宽和高为(wxh)的Rol窗口用(Wx一)的子窗口进行分割,得到约等于人x心个子窗口。利用MaxPooling计算每个子窗口的最大像素点,形成一个币x厅的Featuremap。1.3损失函数FasterR-CNN中的损失分为回归损失和分类损失两大类,分类损失是Softmax,回归损失是SmoothL1造成的损失。其总的损失函数表达式如下:L(tpk0J=卫丁(omJ+ap(1)RPN和ROI的分类损失表达式相同,均是交叉熵损失。但RPN损失是二分类交叉熵损失,ROI损失是多分类交叉熵损失。其表达式如公式(2)所示。Losuz此于2其中,W为总的anchor的数量;在RPN分类损失函数中,P;为第i个anchor的预测分类概率;p「为标签,当anchor为positive时,p;=1,当anchor为negative时,p「=0;Lu(pzp))是二分类交叉熵损失丽数,其表达式如公式(3)所示。乙毗(P懈P萱)=_10g[P萱P乏+(1_P萱)(1_P乏)](3)RPN和ROI的回归损失函数均是由SmoothLILoss计算的,SmoothLILoss解决了在预测值和真实值很接近的时候发生梯度爆炸以及函数在0点不可导影响收敛的问题。SmoothLILoss的表达式如公式(4)所示,函数囹像如图4所示。回归损失函数的表达式如公式(5)所示。0.5ˇ,|x|<1Sm00协凰(宪〉ˇ品宪_-0.5SC「,otherwise(4)Tossu=入童琴PLu(to)=入童琴P「R(t-(5)其中,VW由anchor位置的数量决定;pPTL,.(tu4)表示只有正样本才有边框回归损失;L(tot)=R(i-古,R(i-史是SmoothL1函数;A为权重平衡参数;5是第i个anchor预测的边框回归的参数化坐标;@现代计算机(www.moderncomputer.cn)2021.07中t是第;个anchor的真实框的参数化坐标。s2.0j埕1.0玲0.0-3“-2“-10。2ˇ3图4SmoothL1函数囹像2“实验结果与分析2.1数据集介绍随着车辆目标检测受到了国内外学者的深人研究,如今可供选择的车辆检测数据集也很多,主要包括KITTL、.N-CARS、CompCars和UA-DETRAC等。KITTI数据集采主要是行驶在卡尔斯鲁厄的乡村公路和高速公路上的车辆,数据采集场景在国外,而本实验研究的车辆目标检测的应用场景主要是在国内的街道上,与本实验的实际场景存在偏差。N-CARS和CompCars数据集主要应用在汽车分类,缺少本实验中需要的在道路拥堵,光照太强等不同条件下的稀有数据集。UA-DETRAC数据集既是在国内24座城市拍摄的,也具有道路拥堵,光照强度不同的稀有数据集,与本实验所需实际场景基本相符。因此,本实验所用数据集均截取至UA-DETRAC数据集。其中训练集有10572张,测试集有6705张图片。部分图像如图5所示。本实验所选取的10572张训练集和6705张测试集均有相应的标注文件。图5UA-DETRAC数据集图形图李2.2实验结果本实验中训练所用的硬件配置如下:采用NVIDIACeForceCTX1080TICPU加速,搭建运行环境PyTorch1.6.0、CUDA10.1以及caDNN7,编程语言选择了Python,用Python3.6.9运行程序。由于所用程序数据集标注格式采用的是V0C2007数据集所用标注格式,因此,在训练之前本实验先将所用数据集标注文件的格式改为了VO0C2007数据集标注文件的格式。训练过程中采用VCC16预训练模型,预训练模型的参数权重是VCC16在ImageNet“下训练好的,初始学习率设置为0.001,当迭代次数达到9之后,就将学习率设置为原来的0.1,即0.0001;本实验在GCPU加速下训练迭代14次,得到车辆目标检测的模型。本实验的检测结果均是在Visdom下的可视化窗口呈现的,图6是原始图片的标签图图7是原始图片的预测图囹8是算法改进后的5种loss图9是FasterR-CNN算法改进前后的评估指标mAP的对比图。由图7可以看出车辆检测的概率均在0.9以上,但存在漏检的情况。该情况可能是受到天气条件,遮挡以及光照变化等因素的影响导致的,也可能是数据集在进行预处理时导致的原始图片的信息损失以至于无法识别出来车辆,还有可能是因为原始图片是在监控视频中截取出来的虚化严重无法清晰识别出车辆。由图8可知,roi_loc_loss的损失最大,rpn_cls_loss的损失最小,总损失函数最终控制在0.176左右,图8表明了适当的增加样本数据集有利于降低车辆目标检测的损失和提高车辆目标检测的准确率。由图9可知,基于改进后的FasterR-CNN算法的车辆目标检测的map最终稳定在90.56%,而基于FasterR-CNN算法的车辆目标检测的map最终稳定在90.5095,mAP提高了0.06%。X卫巳pred_img图7检测效果图roi_cls_lossrpn_cls_loss01000“2000“3000“400001000“2000“3000“400001000“2000“3000“4000roi_loc_lossrpn_loc_loss01000“2000“3000“4000。|】1000“2000“3000“4000国85种损失丽数现代计算机(www.moderncomputer.cn)2021.07中@巳图形图李的FasterR-CNN算法完成了对实际场景中的车辆目标检测,有效避免了传统目标检测中出现的过于依赖人工特征提取的问题,有效地提高了车辆目标检测的准确率和速度,为车辆目标检测在智能监控和无人驾驶等领域的应用奠定了基础。虽然检测的准确率和速度已经有了很大的提高,但仍然存在错检.漏检以及无法做到实时检测的情况。因此,未来车辆目标检测的test_map(a)原始mAP(b)改进后mAP难点就在于如何尽可能减小光照.天气等外部因素的图9mAP对比图干扰,以及如何做到实时检测。3“结语本文利用了公开UA-DETRAC数据集,基于改进参考文献:[HWANCXY,YANCM,ZHU3H,etalLRegionletsforgenericobjectdetection[J]IEKEETransactionsonPatternAnalysisandMachineIntelligence,2015,37(10):2071-2084.[2]TAICMANY,YANGCM,RANZATOMA,atal.DeepFace:closingthegaptohuman-levelperformanceinfaceverification[J].IEKEEConferenceonComputerVisionandPatternRecognition.[3.L]:IEEEPress,2014:1701-1708.[3]KAZEMIFM,SAMADIS,PO0O0RREZAHR,atal.VehiclerecognitionusingcurvelettransformandSVM[JIthe4“InternationalCon-ferenceonInformationTechnology[S.L]:IEKEEPress,2007:516-521.[4]A.NEUBECK,L.VANC00L.Efficientnon-maximumsuppression[J]18thInternationalConferenceonPatternRecognition(ICPR「06)(2006),850-855,10.1109/ICPR.2006.479.[5]R.CIRSHICK.Richfeaturehierarchiesforaccurateobjectdetectionandsemanticsegmentation[川ImageNetLarge-ScaleVisualRec-ognitionChallengeWorkshop[3.L]:ICCVPress,2013:10-15.[6]JR.R.UJLINGCS,K.E.A.SANDE,T.CKEVERS,A.W.M.3SMEULDERS.SelectiveSearchforObjectRecognition[J]InternationalJournalofComputerVision.2013(2).[7]R.CIRSHICK.FastR-CNN[JIIEEEInternationalConferenceonComputerVision(ICCV),2015.[8]REN3,HEK,CIRSHICKR.etalLFasterR+CNN:towardsreal-timeobjectdetectionwithregionproposalnetworks[]小InternationalConferenceonNeuralInformationProcessingSystems,2015.[9]JAZAYERIA,CAIH,ZHENGJY,etalLVehicledetectionandtrackingincarvideobasedonmotionmodel[J.IEPEETransactionsonIntelligentTransportationSystems,2011,12(2):583-5935.[10IZHOUY,LIUL,SHAOL,etaLFastautomaticvehicleannotationforurbantrafficsurveillance[J]IKEETransactionsonIntelligentTransportationSystems,2018,19(6):1973-1984.作者简介:单志勇(1972-),男,上海松江人,博士,副教授,研究方向为电磁场与微波技术电磁计算与电磁兼容.天线理论与工程设计通信信号与信息处理通信作者:宫加辉(1997-),女,山东济宁人,硕士研究生,研究方向为囹像处理深度学习,P-mail:1466870362@qq.com收稿日期:2021-03-02修稿日期:2021-03-27现代计算机(www.moderncomputer.cn)2021.07中图形图李VehicleDetectionMethodBasedonFastR-CNNSHANZhiyong,CONCJiahui(DonghuaUniversity,Shanghai201600)Abstract:Asanimportantpartoftrafficmanagementsystem,vehicletargetdetectionhasimportantresearchsignificance.Inordertosolvetheprob-lemoflowaccuracybroughtbytraditionalvehicletargetdetection,avehicletargetdetectionmethodbasedonimprovedFasterR-CNNalgorithmisproposed.BasedontheoriginalFasterR+CNNalgorithmtheimprovedFasterR-CNNalgorithmrandomlyselects960x540,900x500and800x480trainingimagesfortraining,andexpandstheproportionofcandidateregionsinRPN(RegionProposalNetwork)by1:3and3:1.ThemAPofimprovedtargetdetectionis95.692,whichis0.1%higherthanthatofvehicletargetdetectionbasedonFasterR-CNNalgorithm.Keywords:FasterR-CNNAlgorithm;TargetDetection;DeepLearning(上接第73页)ConfusionMatrixClassificationPerformanceEvaluationandPythonImplementationYUYing“YANCTingting“,YANCBoxiong“(1.SchoolofInformationandIntelligentEngineering,UniversityofSanya,Sanya572011;2.AcademicianChenCuoliang「sWorkstation,UniversityofSanya,Sanya572011)Abstract:Thispaperdiscussestheconfusionmatrix,andhowtouseScikit-learntolearnandclassifyconfusionmatrix.ThenintroduceshowtheacCuracy,precisionandrecallarecalculated,andhowtheyrelatetoevaluatingdeeplearningmodels.Keywords:ConfusionMatrix;Scikit-Learn;Accuracy;Precision;Recall现代计算机(www.moderncomputer.cn)2021.07中@